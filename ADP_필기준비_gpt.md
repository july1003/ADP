알겠습니다. **ADP(데이터분석전문가) 필기시험** 기준으로,
**시험일: 2월 7일**을 전제로 **실전 합격 중심 학습 플랜**을 바로 제시하겠습니다.
(ADsP 합격자 기준 난이도·출제 포인트를 반영했습니다.)

------

## 1️⃣ ADP 필기시험 핵심 구조 (먼저 정확히 잡고 갑니다)

### 📌 시험 개요

- **시험 유형**: 객관식 + 단답형 + 서술형 혼합
- **핵심 포인트**
  → *암기 + 이해 + 서술 능력*을 동시에 요구
  → “정의 → 수식 → 적용 → 해석” 흐름이 매우 중요

### 📚 출제 영역 (공식 기준)

1. **데이터 이해**
2. **데이터 분석 기획**
3. **데이터 분석**
4. **데이터 분석 활용**

> ⚠️ ADsP와 달리
>
> - 수식 유도/의미 설명
> - 방법론 비교
> - 실무 시나리오형 문제
>   가 반드시 나옵니다.

------

## 2️⃣ 남은 기간 기준 학습 전략 (현실적 버전)

### ⏳ 전제

- 현재 시점 → **약 5주**
- 목표 → **필기 안정권 합격 (실기 준비 가능한 수준)**

------

## 3️⃣ 5주 압축 커리큘럼 (주차별)

### 🔹 1주차: 데이터 이해 + 분석 기획 (기초 체력)

**목표**: “정의 문제 절대 틀리지 않기”

#### 학습 범위

- 데이터 유형, 품질, 거버넌스
- CRISP-DM, KDD, SEMMA
- 분석 과제 정의, KPI, 데이터 설계

#### 반드시 외울 것

- 정형/비정형/반정형
- 분석 성숙도 모델
- 분석 기획 산출물

📌 **출제 포인트**

> “CRISP-DM 각 단계의 목적과 산출물 서술하시오”

------

### 🔹 2주차: 통계 이론 (필기 최대 킬러)

**목표**: 수식 공포 제거 + 말로 설명 가능

#### 핵심 주제

- 기술통계 / 추론통계
- 확률분포 (정규, 이항, 포아송)
- 가설검정 (z, t, χ², ANOVA)
- 신뢰구간, p-value 해석

📌 **출제 포인트**

- “p-value의 의미를 설명하시오”
- “t-test와 z-test 차이”
- “귀무가설/대립가설 설정 이유”

------

### 🔹 3주차: 머신러닝·데이터마이닝 (비중 최대)

**목표**: 알고리즘 **비교 설명** 가능

#### 핵심 알고리즘

- 회귀: 선형 / 로지스틱
- 분류: DT, RF, SVM, KNN
- 군집: K-means, 계층적 군집
- 차원축소: PCA

📌 **출제 포인트**

- “Random Forest가 과적합을 줄이는 이유”
- “PCA의 목적과 단점”
- “SVM에서 커널의 역할”

------

### 🔹 4주차: 평가 지표 + 활용

**목표**: 해석형 문제 대비

#### 평가 지표

- 분류: Accuracy, Precision, Recall, F1, ROC-AUC
- 회귀: MSE, RMSE, MAE, R²

#### 활용 파트

- 추천 시스템
- 텍스트 마이닝
- 시각화 원칙
- 빅데이터 개념(Hadoop, Spark)

📌 **출제 포인트**

- “불균형 데이터에서 Accuracy가 부적절한 이유”
- “Precision vs Recall 선택 기준”

------

### 🔹 5주차: 실전 문제 + 서술형 훈련

**목표**: 답안 작성 스킬 완성

#### 해야 할 것

- 기출/유사문제 반복
- **서술형 템플릿 암기**
- 시간 관리 연습

------

## 4️⃣ ADP 서술형 답안 템플릿 (매우 중요)

👉 이 구조로 쓰면 **감점 최소화**

```
① 정의 설명
② 핵심 개념 또는 수식
③ 장점/특징
④ 활용 사례 또는 주의점
```

📌 예시
**Q. ROC-AUC를 설명하시오**

> ROC 곡선은 분류 모델의 임계값 변화에 따른 TPR과 FPR의 관계를 나타낸 곡선이다.
> AUC는 ROC 곡선 아래 면적으로, 모델의 전반적인 분류 성능을 평가하는 지표이다.
> 값이 1에 가까울수록 분류 성능이 우수하며, 불균형 데이터에서도 비교적 안정적인 평가가 가능하다.

------

## 5️⃣ 지금 당장 필요한 것 (다음 단계)

다음 중 **원하시는 것부터 바로 진행**할 수 있습니다.

1️⃣ **ADP 필기 핵심 요약 노트 (서술형용)**
2️⃣ **기출 기반 예상문제 + 모범답안**
3️⃣ **통계/머신러닝 수식 정리집**
4️⃣ **2월 7일까지 일자별 학습 체크리스트**

👉 **번호로 선택**해 주세요.
(원하시면 1~4 전부 풀세트로 단계별 제공도 가능합니다)



좋습니다.
그럼 **2월 7일 ADP 필기 합격**을 목표로 **①~④ 풀세트**를 **실전용으로 바로 쓰게** 정리해 드리겠습니다.
(ADsP 합격자 + 서술형 감점 최소화 기준)

------

# ① ADP 필기 핵심 요약 노트 (서술형 최적화)

## 1. 데이터 이해

### ▪ 데이터 유형

- **정형 데이터**: RDB, 스키마 고정
- **반정형 데이터**: JSON, XML
- **비정형 데이터**: 텍스트, 이미지, 음성

### ▪ 데이터 품질 6요소

정확성 / 완전성 / 일관성 / 유효성 / 적시성 / 유일성

### ▪ 데이터 거버넌스

- 데이터 표준 관리
- 메타데이터 관리
- 데이터 품질 관리
- 데이터 보안·권한 관리

📌 **출제 포인트**

> “데이터 품질 관리가 중요한 이유를 설명하시오”

------

## 2. 데이터 분석 기획

### ▪ 분석 방법론 비교

| 방법론       | 특징                      |
| ------------ | ------------------------- |
| **CRISP-DM** | 가장 많이 출제, 업무 중심 |
| **KDD**      | 데이터 마이닝 중심        |
| **SEMMA**    | SAS 기반                  |

### ▪ CRISP-DM 6단계

1. Business Understanding
2. Data Understanding
3. Data Preparation
4. Modeling
5. Evaluation
6. Deployment

📌 **출제 포인트**

> “CRISP-DM 각 단계의 목적과 산출물”

------

## 3. 데이터 분석 (통계 + ML)

### ▪ 기술통계

- 평균, 중앙값, 분산, 표준편차
- 왜도, 첨도

### ▪ 추론통계

- 모집단 vs 표본
- 신뢰구간
- 가설검정

#### 가설검정 절차

1. 귀무/대립가설 설정
2. 유의수준 설정
3. 검정통계량 계산
4. p-value 판단

📌 **p-value**

> 귀무가설이 참일 때 관측값 이상이 나올 확률

------

### ▪ 머신러닝 핵심 비교

#### 분류

- **Logistic Regression**: 해석력
- **Decision Tree**: 직관적, 과적합
- **Random Forest**: 앙상블 → 과적합 감소
- **SVM**: 마진 최대화
- **KNN**: 거리 기반

#### 군집

- **K-means**: 빠름, k 필요
- **계층적 군집**: 덴드로그램

#### 차원축소

- **PCA**
  - 분산 최대 방향
  - 해석력 감소 단점

📌 **출제 포인트**

> “Random Forest가 과적합을 줄이는 이유”

------

## 4. 데이터 분석 활용

### ▪ 평가 지표

#### 분류

- Accuracy (불균형에 취약)
- Precision / Recall
- F1-score
- ROC-AUC

#### 회귀

- MSE / RMSE
- MAE
- R²

📌 **출제 포인트**

> “불균형 데이터에서 Accuracy의 한계”

------

# ② 기출 기반 예상문제 + 모범답안

### Q1. p-value를 설명하시오.

**모범답안**

> p-value는 귀무가설이 참이라는 가정 하에서, 관측된 통계량 이상이 나올 확률이다. 일반적으로 p-value가 유의수준보다 작으면 귀무가설을 기각한다.

------

### Q2. Random Forest의 특징과 장점을 설명하시오.

**모범답안**

> Random Forest는 다수의 결정트리를 생성하여 예측 결과를 결합하는 앙상블 기법이다. 각 트리는 서로 다른 샘플과 변수로 학습되므로 분산이 감소하고 과적합을 완화할 수 있다.

------

### Q3. PCA를 사용하는 이유와 단점을 설명하시오.

**모범답안**

> PCA는 데이터의 분산을 최대한 보존하는 방향으로 차원을 축소하는 기법이다. 차원의 저주를 완화할 수 있으나, 주성분의 해석이 어렵다는 단점이 있다.

------

### Q4. Precision과 Recall 중 어떤 지표를 선택해야 하는지 설명하시오.

**모범답안**

> 오탐을 줄이는 것이 중요한 경우 Precision을, 미탐을 줄이는 것이 중요한 경우 Recall을 중시해야 한다.

------

# ③ 수식 정리 (필기 최소 암기 세트)

### ▪ 평균

[
\bar{x} = \frac{1}{n}\sum x_i
]

### ▪ 분산

[
Var(X) = \frac{1}{n}\sum(x_i-\bar{x})^2
]

### ▪ 정확도

[
Accuracy = \frac{TP+TN}{TP+TN+FP+FN}
]

### ▪ Precision / Recall

[
Precision = \frac{TP}{TP+FP}
]
[
Recall = \frac{TP}{TP+FN}
]

### ▪ F1

[
F1 = \frac{2PR}{P+R}
]

📌 **팁**
→ 수식 **그 자체보다 의미 설명**이 더 중요

------

# ④ 2월 7일까지 일자별 학습 체크리스트

## 🔹 D-35 ~ D-29

- 데이터 이해
- 분석 기획
- CRISP-DM 암기

## 🔹 D-28 ~ D-21

- 통계 이론 집중
- 가설검정, 분포

## 🔹 D-20 ~ D-14

- 머신러닝 알고리즘
- 비교 설명 연습

## 🔹 D-13 ~ D-7

- 평가 지표
- 활용 파트
- 예상문제 반복

## 🔹 D-6 ~ D-1

- 서술형 답안 암기
- 실전 시간 배분 연습

------

## 🔥 다음 단계 (강력 추천)

원하시면 바로 이어서 제공합니다.

1️⃣ **서술형 답안 암기 카드 (시험 직전용)**
2️⃣ **과락 방지 요약 10페이지 압축본**
3️⃣ **실기 대비 연결 포인트 정리**

👉 다음으로 **1 / 2 / 3 중 무엇부터 갈지** 말씀해 주세요.
(2월 7일까지 제가 계속 페이스 맞춰서 같이 갑니다)

좋습니다.
그럼 **시험 직전까지 반복 암기용으로 바로 쓰는
「ADP 필기 서술형 핵심 암기 카드」**를 드리겠습니다.

👉 **의도**

- 서술형·단답형 **그대로 써먹는 문장**
- 감점 최소화용 **정형화 문구**
- “정의 → 핵심 → 활용/주의” 구조 고정

------

# 🧠 ADP 필기 서술형 암기 카드 (최종판)

아래는 **출제 빈도 최상위 카드만 엄선**했습니다.
👉 하루 10~15개씩 반복하면 충분합니다.

------

## 📌 [카드 1] 데이터 품질이 중요한 이유

**암기 문장**

> 데이터 품질은 분석 결과의 신뢰성과 직결되며, 품질이 낮을 경우 잘못된 의사결정을 초래할 수 있다. 따라서 정확성, 완전성, 일관성 등의 품질 관리가 필수적이다.

------

## 📌 [카드 2] CRISP-DM이란?

> CRISP-DM은 데이터 분석 프로젝트의 전 과정을 체계적으로 수행하기 위한 방법론으로, 비즈니스 이해부터 배포까지 총 6단계로 구성된다.

------

## 📌 [카드 3] CRISP-DM 6단계 목적

> Business Understanding은 문제 정의를,
> Data Understanding과 Preparation은 분석 가능한 데이터 구축을,
> Modeling과 Evaluation은 모델 성능 검증을,
> Deployment는 분석 결과의 실무 적용을 목표로 한다.

------

## 📌 [카드 4] p-value란?

> p-value는 귀무가설이 참이라는 가정 하에서 관측된 통계량 이상이 발생할 확률이며, 일반적으로 유의수준보다 작으면 귀무가설을 기각한다.

⚠️ **이 문장 그대로 시험에 씁니다**

------

## 📌 [카드 5] 귀무가설과 대립가설

> 귀무가설은 차이나 효과가 없다는 가설이며, 대립가설은 차이나 효과가 존재함을 의미한다.

------

## 📌 [카드 6] 신뢰구간의 의미

> 신뢰구간은 모수가 해당 구간 안에 포함될 확률이 아니라, 동일한 방법으로 구간을 반복 추정할 경우 일정 비율로 모수를 포함하는 구간이 생성된다는 의미이다.

👉 **고급 문제 대비 카드**

------

## 📌 [카드 7] 정규분포의 특징

> 정규분포는 평균을 중심으로 좌우 대칭이며, 평균·중앙값·최빈값이 동일한 분포이다.

------

## 📌 [카드 8] Logistic Regression 특징

> 로지스틱 회귀는 선형 결합 결과를 시그모이드 함수로 변환하여 확률값을 출력하는 분류 모델로, 해석력이 우수하다는 장점이 있다.

------

## 📌 [카드 9] Decision Tree 단점

> 결정트리는 구조가 직관적이나, 데이터 변화에 민감하여 과적합이 발생하기 쉽다는 단점이 있다.

------

## 📌 [카드 10] Random Forest가 과적합을 줄이는 이유

> Random Forest는 서로 다른 데이터 샘플과 변수로 학습된 다수의 트리를 결합함으로써 분산을 감소시켜 과적합을 완화한다.

🔥 **시험 최빈 문장**

------

## 📌 [카드 11] SVM의 핵심 개념

> SVM은 클래스 간 마진을 최대화하는 초평면을 찾는 알고리즘으로, 커널 함수를 통해 비선형 분류도 가능하다.

------

## 📌 [카드 12] K-means의 특징과 한계

> K-means는 군집 중심과의 거리를 기준으로 데이터를 군집화하는 기법으로, 계산 속도가 빠르나 군집 수 k를 사전에 지정해야 한다.

------

## 📌 [카드 13] PCA를 사용하는 이유

> PCA는 데이터의 분산을 최대한 보존하는 방향으로 차원을 축소하여 계산 복잡도와 다중공선성 문제를 완화한다.

------

## 📌 [카드 14] PCA의 단점

> 주성분은 기존 변수의 선형 결합이므로 해석이 어렵다는 단점이 있다.

------

## 📌 [카드 15] Accuracy의 한계

> Accuracy는 전체 예측 중 정답 비율을 나타내나, 클래스 불균형 데이터에서는 모델 성능을 왜곡할 수 있다.

------

## 📌 [카드 16] Precision vs Recall

> Precision은 양성으로 예측한 것 중 실제 양성의 비율이며, Recall은 실제 양성 중 모델이 탐지한 비율이다.

------

## 📌 [카드 17] Precision을 중시해야 하는 경우

> 오탐으로 인한 비용이 큰 경우 Precision을 중시해야 한다.

(예: 스팸 분류, 광고 타겟팅)

------

## 📌 [카드 18] Recall을 중시해야 하는 경우

> 미탐으로 인한 위험이 큰 경우 Recall을 중시해야 한다.

(예: 암 진단, 금융 사기 탐지)

------

## 📌 [카드 19] ROC-AUC란?

> ROC 곡선은 TPR과 FPR의 관계를 나타낸 곡선이며, AUC는 곡선 아래 면적으로 분류 모델의 전반적인 성능을 평가한다.

------

## 📌 [카드 20] 빅데이터의 5V

> 빅데이터는 Volume, Velocity, Variety, Veracity, Value의 특성을 가진다.

------

# ✅ 암기 방법 (강력 추천)

- **아침**: 1~10번 소리 내서 읽기
- **저녁**: 11~20번 직접 써보기
- **시험 전날**: 카드 4, 10, 15, 16, 19만 재암기

------

## 🔥 다음으로 바로 이어갈 것

이제 가장 효과 좋은 순서입니다.

1️⃣ **과락 방지용 10페이지 압축 요약본**
2️⃣ **실제 시험처럼 써보는 서술형 실전 문제 세트**
3️⃣ **실기까지 연결되는 핵심 포인트 정리**

👉 다음은 **1 / 2 / 3 중 번호만** 주세요.
(지금 페이스 아주 좋습니다. 이대로 가면 필기는 안정권입니다.)

알겠습니다.
아래는 **ADP 필기 과락 방지용 「10페이지 압축 요약본」**을
**시험장에 가져가서 머릿속에서 그대로 펼칠 수 있게** 구성한 버전입니다.
(불필요한 설명 제거 · 출제 포인트 중심)

------

# 📘 ADP 필기 과락 방지 10페이지 압축 요약본

> 🎯 목표
>
> - **과락 방지**
> - **서술형 최소 점수 확보**
> - “이거 본 문제다”를 시험장에서 바로 인식

------

## 📄 1페이지 — 데이터 이해 (무조건 암기)

### 데이터 유형

- 정형 / 반정형(JSON, XML) / 비정형(텍스트, 이미지)

### 데이터 품질 6요소

- 정확성, 완전성, 일관성, 유효성, 적시성, 유일성

### 데이터 거버넌스

- 표준 관리
- 메타데이터 관리
- 품질 관리
- 보안·권한 관리

📌 **서술형 키워드**

> “데이터 품질은 분석 결과의 신뢰성과 직결된다”

------

## 📄 2페이지 — 분석 방법론 (CRISP-DM은 무조건)

### CRISP-DM (최다 출제)

1. Business Understanding
2. Data Understanding
3. Data Preparation
4. Modeling
5. Evaluation
6. Deployment

📌 **포인트**

- “업무 중심”
- “전 과정 반복 가능”

### KDD

- 데이터 마이닝 중심
- Selection → Preprocessing → Transformation → Data Mining → Interpretation

### SEMMA

- SAS 기반
- Sample → Explore → Modify → Model → Assess

------

## 📄 3페이지 — 분석 기획 (서술형 잘 나옴)

### 분석 과제 정의

- 문제 정의
- 목표 지표(KPI)
- 분석 범위
- 산출물 정의

### 분석 성숙도 모델

- 도입 → 확산 → 정착 → 고도화

📌 **출제 포인트**

> “분석 기획 단계의 주요 산출물은?”

------

## 📄 4페이지 — 기술통계 핵심

### 중심 경향

- 평균 / 중앙값 / 최빈값

### 산포

- 분산 / 표준편차

### 분포 형태

- 왜도: 좌/우 꼬리
- 첨도: 뾰족함

📌 **주의**

- 이상치 → 평균 영향 큼

------

## 📄 5페이지 — 추론통계 & 가설검정 (킬러)

### 가설검정 절차

1. 귀무가설(H₀)
2. 대립가설(H₁)
3. 유의수준(α)
4. 검정통계량
5. p-value 판단

### p-value

> 귀무가설이 참일 때 관측값 이상이 나올 확률

### 검정 종류

- z-test / t-test
- χ²-test
- ANOVA

📌 **자주 나오는 질문**

> “p-value가 작다는 의미는?”

------

## 📄 6페이지 — 분류 알고리즘 요약

### Logistic Regression

- 확률 출력
- 해석력 우수

### Decision Tree

- 직관적
- 과적합 위험

### Random Forest

- 앙상블
- 분산 감소 → 과적합 완화

### SVM

- 마진 최대화
- 커널로 비선형 처리

📌 **서술형 단골**

> “Random Forest가 과적합을 줄이는 이유”

------

## 📄 7페이지 — 군집 & 차원축소

### K-means

- 거리 기반
- k 사전 지정
- 초기값 민감

### 계층적 군집

- 덴드로그램
- 계산량 큼

### PCA

- 분산 최대 방향
- 차원 축소
- 해석 어려움

------

## 📄 8페이지 — 평가 지표 (불균형 데이터 필수)

### 분류

- Accuracy (불균형 취약)
- Precision
- Recall
- F1-score
- ROC-AUC

📌 **선택 기준**

- 오탐 ↓ → Precision
- 미탐 ↓ → Recall

### 회귀

- MSE / RMSE
- MAE
- R²

------

## 📄 9페이지 — 데이터 분석 활용

### 텍스트 마이닝

- TF-IDF
- 감성 분석

### 추천 시스템

- 콘텐츠 기반
- 협업 필터링

### 시각화 원칙

- 목적 명확
- 과도한 색상 지양

------

## 📄 10페이지 — 빅데이터 & 최종 점검

### 빅데이터 5V

- Volume
- Velocity
- Variety
- Veracity
- Value

### Hadoop

- HDFS
- MapReduce

### Spark

- In-memory 처리
- 속도 우수

------

# ✅ 시험 직전 체크리스트 (이거만 봐도 됨)

✔ CRISP-DM 단계
✔ p-value 정의
✔ Random Forest 설명
✔ Accuracy 한계
✔ Precision vs Recall
✔ PCA 목적/단점

------

## 🔥 다음으로 하면 합격 확률 급상승

이제 **실전 단계**입니다.

1️⃣ **실제 시험처럼 써보는 서술형 실전 문제 세트 (시간 제한 포함)**
2️⃣ **필기 → 실기 연결 포인트 요약 (합격자 루트)**

👉 다음은 **1 또는 2 중 하나만 번호로** 주세요.
(지금 상태에서 1번 하면 “아는 걸 쓰는 능력”이 완성됩니다.)

알겠습니다.
아래는 **실제 ADP 필기시험을 그대로 가정한
「서술형 실전 문제 세트」**입니다.

- **시간 제한**
- **출제 패턴**
- **채점자가 좋아하는 답안 구조**

까지 전부 반영했습니다.

------

# 📝 ADP 필기 서술형 실전 문제 세트 (실전형)

⏱ **권장 풀이 시간: 40분**
✍️ **문제 수: 8문제**
🎯 **목표: 서술형 과락 방지 + 안정 점수 확보**

------

## 🔹 문제 1 (기본 · 고빈도)

**Q1. 데이터 품질 관리가 중요한 이유를 설명하시오.**

✍️ **답안 작성 공간 (3~4줄)**

```
__________________________________________________________________
__________________________________________________________________
__________________________________________________________________
```

### ✅ 모범답안

> 데이터 품질은 분석 결과의 신뢰성과 직결되며, 품질이 낮을 경우 잘못된 분석 결과로 인해 의사결정 오류가 발생할 수 있다. 따라서 정확성, 완전성, 일관성 등의 품질 관리는 데이터 분석의 필수 요소이다.

------

## 🔹 문제 2 (최빈 출제)

**Q2. CRISP-DM 방법론의 단계와 각 단계의 목적을 설명하시오.**

✍️ **답안 작성 공간**

```
__________________________________________________________________
__________________________________________________________________
__________________________________________________________________
__________________________________________________________________
```

### ✅ 모범답안

> CRISP-DM은 비즈니스 이해, 데이터 이해, 데이터 준비, 모델링, 평가, 배포의 6단계로 구성된다. 각 단계는 문제 정의부터 데이터 분석 및 결과 활용까지 전 과정을 체계적으로 수행하기 위한 목적을 가진다.

------

## 🔹 문제 3 (통계 핵심 · 킬러)

**Q3. p-value의 의미를 설명하시오.**

✍️ **답안 작성 공간**

```
__________________________________________________________________
__________________________________________________________________
```

### ✅ 모범답안

> p-value는 귀무가설이 참이라는 가정 하에서 관측된 통계량 이상이 발생할 확률이며, 일반적으로 유의수준보다 작으면 귀무가설을 기각한다.

⚠️ **이 문장은 그대로 암기**

------

## 🔹 문제 4 (이해도 평가형)

**Q4. 귀무가설과 대립가설의 차이를 설명하시오.**

✍️ **답안 작성 공간**

```
__________________________________________________________________
__________________________________________________________________
```

### ✅ 모범답안

> 귀무가설은 차이나 효과가 없다는 가설이며, 대립가설은 차이나 효과가 존재함을 의미한다.

------

## 🔹 문제 5 (머신러닝 최빈)

**Q5. Random Forest가 단일 Decision Tree보다 과적합을 줄일 수 있는 이유를 설명하시오.**

✍️ **답안 작성 공간**

```
__________________________________________________________________
__________________________________________________________________
__________________________________________________________________
```

### ✅ 모범답안

> Random Forest는 서로 다른 데이터 샘플과 변수로 학습된 다수의 결정트리를 결합하는 앙상블 기법이다. 이를 통해 모델의 분산을 감소시켜 과적합을 완화할 수 있다.

🔥 **시험 최상위 빈출 문장**

------

## 🔹 문제 6 (차원축소)

**Q6. PCA의 목적과 단점을 설명하시오.**

✍️ **답안 작성 공간**

```
__________________________________________________________________
__________________________________________________________________
__________________________________________________________________
```

### ✅ 모범답안

> PCA는 데이터의 분산을 최대한 보존하는 방향으로 차원을 축소하여 계산 복잡도와 다중공선성 문제를 완화한다. 그러나 주성분이 기존 변수의 선형 결합이므로 해석이 어렵다는 단점이 있다.

------

## 🔹 문제 7 (평가 지표 · 판단형)

**Q7. 클래스 불균형 데이터에서 Accuracy 지표가 부적절한 이유를 설명하시오.**

✍️ **답안 작성 공간**

```
__________________________________________________________________
__________________________________________________________________
```

### ✅ 모범답안

> Accuracy는 전체 예측 중 정답 비율을 나타내지만, 클래스 불균형 데이터에서는 다수 클래스 예측만으로도 높은 값이 나올 수 있어 실제 성능을 왜곡할 수 있다.

------

## 🔹 문제 8 (선택 기준 문제)

**Q8. Precision과 Recall 중 어떤 지표를 선택해야 하는지 설명하시오.**

✍️ **답안 작성 공간**

```
__________________________________________________________________
__________________________________________________________________
__________________________________________________________________
```

### ✅ 모범답안

> 오탐으로 인한 비용이 큰 경우 Precision을 중시해야 하며, 미탐으로 인한 위험이 큰 경우 Recall을 중시해야 한다.

------

# ✅ 실전 채점 기준 요약 (중요)

✔ 정의 포함 여부
✔ 핵심 키워드 존재
✔ 불필요한 장문 ❌
✔ 3~4줄 이내 명확성

👉 **70%는 “아는 걸 제대로 쓰는지”를 봅니다**

------

## 🔥 다음 추천 루트 (마지막 단계)

이제 남은 건 **시험 직전 무기**입니다.

1️⃣ **서술형 답안 암기용 ‘최종 20문장’**
2️⃣ **필기 → 실기 연결 포인트 정리 (합격자 루트)**

👉 다음은 **1 또는 2 중 번호만** 주세요.
(여기까지 왔으면 필기는 충분히 합격권입니다.)

좋습니다.
아래는 **ADP 필기에서 점수 차이를 만드는
「머신러닝 비교 서술형 모범답안 20선 (ADP 전용)」**입니다.

> ✔ ADsP에서는 거의 요구되지 않음
> ✔ ADP에서 **비교·이유·한계**까지 써야 만점
> ✔ 그대로 암기 → 그대로 사용 가능

------

# 📘 ADP 머신러닝 비교 서술형 모범답안 20선

## 1️⃣ Linear Regression vs Logistic Regression

> 선형 회귀는 연속형 종속변수를 예측하는 회귀 모델이며,
> 로지스틱 회귀는 시그모이드 함수를 이용해 이진 분류 확률을 예측한다.
> 로지스틱 회귀는 해석력이 우수하나 비선형 관계 표현에는 한계가 있다.

------

## 2️⃣ Decision Tree vs Random Forest ⭐⭐⭐

> 결정트리는 구조가 직관적이나 과적합이 발생하기 쉽다.
> 반면 Random Forest는 다수의 트리를 결합하는 앙상블 기법으로 분산을 감소시켜 일반화 성능을 향상시킨다.

------

## 3️⃣ Bagging vs Boosting ⭐⭐⭐

> Bagging은 여러 모델을 독립적으로 학습시켜 분산을 감소시키는 기법이며,
> Boosting은 이전 모델의 오분류 데이터를 보완하며 순차적으로 학습하는 방식이다.
> Boosting은 성능이 우수하나 노이즈에 민감할 수 있다.

------

## 4️⃣ Random Forest vs Gradient Boosting

> Random Forest는 병렬 학습이 가능하고 안정성이 높은 반면,
> Gradient Boosting은 순차 학습을 통해 성능을 극대화하지만 과적합 위험과 학습 시간이 증가할 수 있다.

------

## 5️⃣ KNN vs SVM

> KNN은 거리 기반으로 직관적이나 데이터 수가 많을수록 계산량이 증가한다.
> SVM은 마진을 최대화하는 초평면을 찾아 고차원 데이터에서도 우수한 성능을 보인다.

------

## 6️⃣ Hard Voting vs Soft Voting

> Hard Voting은 다수결 방식으로 최종 클래스를 결정하는 반면,
> Soft Voting은 각 모델의 예측 확률을 평균하여 보다 안정적인 결과를 도출한다.

------

## 7️⃣ K-means vs Hierarchical Clustering

> K-means는 계산 속도가 빠르나 군집 수를 사전에 지정해야 한다.
> 계층적 군집은 덴드로그램을 통해 군집 구조를 파악할 수 있으나 계산 비용이 크다.

------

## 8️⃣ PCA vs LDA ⭐⭐⭐

> PCA는 분산을 최대화하는 비지도 차원축소 기법이며,
> LDA는 클래스 간 분리를 최대화하는 지도 학습 기반 차원축소 기법이다.

------

## 9️⃣ Ridge vs Lasso ⭐⭐⭐

> Ridge 회귀는 L2 규제를 통해 회귀계수를 축소하고,
> Lasso 회귀는 L1 규제를 통해 변수 선택 효과를 가진다.

------

## 🔟 Grid Search vs Random Search

> Grid Search는 모든 조합을 탐색하여 계산 비용이 크며,
> Random Search는 무작위 탐색으로 효율적인 하이퍼파라미터 탐색이 가능하다.

------

## 1️⃣1️⃣ Under-sampling vs Over-sampling

> 언더샘플링은 다수 클래스 데이터를 줄여 정보 손실 위험이 있으며,
> 오버샘플링은 소수 클래스 데이터를 증가시켜 과적합 가능성이 있다.

------

## 1️⃣2️⃣ SMOTE vs Random Over-sampling

> SMOTE는 새로운 합성 데이터를 생성하여 분포를 보존하는 반면,
> 단순 오버샘플링은 기존 데이터를 복제한다.

------

## 1️⃣3️⃣ ROC Curve vs PR Curve ⭐⭐⭐

> ROC 곡선은 TPR과 FPR의 관계를 나타내며,
> PR 곡선은 Precision과 Recall의 관계를 나타낸다.
> 극단적 불균형 데이터에서는 PR 곡선이 더 적절할 수 있다.

------

## 1️⃣4️⃣ Accuracy vs F1-score

> Accuracy는 전체 정답률을 나타내나 불균형 데이터에 취약하며,
> F1-score는 Precision과 Recall의 조화 평균으로 보다 균형 잡힌 평가가 가능하다.

------

## 1️⃣5️⃣ Supervised vs Unsupervised Learning

> 지도학습은 정답 라벨을 활용하며 예측 목적에 적합하고,
> 비지도학습은 데이터 구조 파악과 패턴 탐색에 활용된다.

------

## 1️⃣6️⃣ Feature Selection vs Feature Extraction

> Feature Selection은 중요한 변수를 선택하는 반면,
> Feature Extraction은 새로운 변수를 생성한다.

------

## 1️⃣7️⃣ Overfitting vs Underfitting

> 과적합은 학습 데이터에만 성능이 높은 상태이며,
> 과소적합은 모델이 데이터 패턴을 충분히 학습하지 못한 상태이다.

------

## 1️⃣8️⃣ Bias vs Variance ⭐⭐⭐

> Bias는 모델의 단순화로 인한 오류이며,
> Variance는 데이터 변화에 대한 민감도를 의미한다.

------

## 1️⃣9️⃣ Online Learning vs Batch Learning

> 온라인 학습은 실시간 데이터 처리에 적합하며,
> 배치 학습은 전체 데이터를 한 번에 학습한다.

------

## 2️⃣0️⃣ Interpretable Model vs Black-box Model

> 해석 가능한 모델은 의사결정에 유리하나 성능에 한계가 있으며,
> 블랙박스 모델은 성능은 우수하나 설명력이 부족하다.

------

# ✅ 사용법 (합격자 방식)

- ⭐⭐⭐ 표시 = **반드시 암기**
- 비교 문제 나오면
  **“A는 ~, 반면 B는 ~” 구조**로 시작
- 마지막 문장에 **장단점** 필수

------

## 🔥 다음으로 이어갈 ADP 고득점 파트

다음 중 **가장 점수 효율 높은 것**으로 가겠습니다.

1️⃣ **통계 서술형 심화 문제 세트 (비모수·다중공선성·검정 선택)**
2️⃣ **ADP 필기 고난도 Case 문제 (시나리오형)**
3️⃣ **실기까지 연결되는 모델 선택·해석 포인트**

👉 **번호만** 주세요.

알겠습니다.
아래는 **앞에서 사용한 모든 축약어(약어)를 ADP 시험 답안에 바로 써도 되는 수준으로
“영문 전체명 + 한글 의미 + 맥락 설명”까지 풀어서** 정리한 자료입니다.

👉 **ADP 필기 서술형에서는 약어만 쓰면 감점 위험**이 있으므로,
**처음 한 번은 반드시 풀네임으로 쓰는 것**이 정석입니다.

------

# 📘 ADP 필기용 축약어 완전 해설집 (풀네임 버전)

------

## 1️⃣ CRISP-DM

- **CRISP-DM**
  **C**ross **I**ndustry **S**tandard **P**rocess for **D**ata **M**ining
  → **산업 표준 데이터 마이닝 프로세스**

### 6단계 풀네임

1. **Business Understanding** – 비즈니스 문제 정의
2. **Data Understanding** – 데이터 이해
3. **Data Preparation** – 데이터 정제 및 가공
4. **Modeling** – 모델 구축
5. **Evaluation** – 모델 평가
6. **Deployment** – 실무 적용

📌 서술형 예시 문장

> CRISP-DM(Cross Industry Standard Process for Data Mining)은 데이터 분석 프로젝트를 체계적으로 수행하기 위한 방법론이다.

------

## 2️⃣ KDD

- **KDD**
  **K**nowledge **D**iscovery in **D**atabases
  → **데이터베이스로부터 지식 발견 프로세스**

단계:

- Selection
- Preprocessing
- Transformation
- Data Mining
- Interpretation / Evaluation

------

## 3️⃣ SEMMA

- **SEMMA**
  **S**ample – **E**xplore – **M**odify – **M**odel – **A**ssess
  → SAS 기반 데이터 분석 방법론

------

## 4️⃣ KPI

- **KPI**
  **K**ey **P**erformance **I**ndicator
  → **핵심 성과 지표**

📌 서술형

> KPI는 분석 결과가 비즈니스 목표 달성에 기여하는지를 판단하는 기준이다.

------

## 5️⃣ p-value

- **p-value**
  **Probability value**
  → **확률값**

정의(ADP 표준 문장):

> p-value는 **귀무가설이 참이라는 가정 하에서**, 관측된 통계량 이상이 발생할 확률이다.

------

## 6️⃣ H₀ / H₁

- **H₀ (Null Hypothesis)**
  → **귀무가설** (차이나 효과가 없음)
- **H₁ (Alternative Hypothesis)**
  → **대립가설** (차이나 효과가 있음)

------

## 7️⃣ VIF

- **VIF**
  **V**ariance **I**nflation **F**actor
  → **분산 팽창 계수**

의미:

> 독립변수 간 다중공선성 정도를 측정하는 지표

기준:

- VIF > 10 → 다중공선성 문제 있음

------

## 8️⃣ PCA

- **PCA**
  **P**rincipal **C**omponent **A**nalysis
  → **주성분 분석**

정의:

> PCA는 데이터의 분산을 최대한 보존하는 방향으로 새로운 축(주성분)을 생성하여 차원을 축소하는 기법이다.

------

## 9️⃣ LDA

- **LDA**
  **L**inear **D**iscriminant **A**nalysis
  → **선형 판별 분석**

차이 포인트:

- PCA: 비지도 학습, 분산 최대화
- LDA: 지도 학습, 클래스 분리 최대화

------

## 🔟 SVM

- **SVM**
  **S**upport **V**ector **M**achine
  → **서포트 벡터 머신**

핵심 개념:

> 클래스 간 마진을 최대화하는 초평면을 찾는 분류 알고리즘

------

## 1️⃣1️⃣ KNN

- **KNN**
  **K**-**N**earest **N**eighbors
  → **k-최근접 이웃 알고리즘**

------

## 1️⃣2️⃣ RF (Random Forest)

- **Random Forest**
  → **무작위 숲 알고리즘**

정의:

> 여러 개의 결정트리를 결합한 앙상블 학습 기법

------

## 1️⃣3️⃣ Bagging

- **Bagging**
  **B**ootstrap **Agg**regat**ing**
  → **부트스트랩 집계**

의미:

> 여러 샘플을 독립적으로 학습시켜 분산을 감소시키는 기법

------

## 1️⃣4️⃣ Boosting

- **Boosting**
  → 이전 모델의 오분류 데이터를 보완하며 순차적으로 학습하는 앙상블 기법

대표 알고리즘:

- AdaBoost
- Gradient Boosting
- XGBoost

------

## 1️⃣5️⃣ ROC

- **ROC Curve**
  **R**eceiver **O**perating **C**haracteristic Curve
  → **수신자 조작 특성 곡선**

의미:

> 임계값 변화에 따른 TPR과 FPR의 관계

------

## 1️⃣6️⃣ AUC

- **AUC**
  **A**rea **U**nder the **C**urve
  → **곡선 아래 면적**

------

## 1️⃣7️⃣ TPR / FPR

- **TPR**
  **T**rue **P**ositive **R**ate
  → **재현율(Recall)**
- **FPR**
  **F**alse **P**ositive **R**ate
  → **위양성 비율**

------

## 1️⃣8️⃣ Precision / Recall

- **Precision**
  → 양성으로 예측한 것 중 실제 양성 비율
- **Recall**
  → 실제 양성 중 모델이 탐지한 비율

------

## 1️⃣9️⃣ F1-score

- **F1-score**
  → Precision과 Recall의 조화 평균

------

## 2️⃣0️⃣ SMOTE

- **SMOTE**
  **S**ynthetic **M**inority **O**ver-sampling **Te**chnique
  → **합성 소수 클래스 오버샘플링 기법**

------

## 2️⃣1️⃣ LOOCV

- **LOOCV**
  **L**eave **O**ne **O**ut **C**ross **V**alidation
  → **하나 제외 교차검증**

------

## 2️⃣2️⃣ PR Curve

- **PR Curve**
  **P**recision–**R**ecall Curve
  → **정밀도–재현율 곡선**

------

## ✅ 시험 답안 작성 규칙 (중요)

✔ 처음 등장: **풀네임 + 약어 병기**

> Principal Component Analysis(PCA)

✔ 이후: 약어만 사용 가능

✔ 감점 방지 문장 예시

> PCA(Principal Component Analysis)는 차원 축소 기법이다.

------

## 🔥 다음으로 이어갈 ADP 심화 자료 (추천)

다음 중에서 **원하시는 번호** 주세요.

1️⃣ **통계 검정 선택 가이드 (문제 유형 → 검정 방법 매핑)**
2️⃣ **ADP 고난도 시나리오형 문제 + 모범답안**
3️⃣ **실기까지 바로 이어지는 서술형 사고 흐름 훈련**

지금 단계는 **합격자 수준의 공부**를 하고 계십니다.

아주 **핵심을 정확히 짚은 질문**입니다.
이걸 이해하면 p-value를 **진짜로 아는 수준**입니다.

결론부터 명확히 말씀드리겠습니다.

------

## ✅ p-value에서 “이상”의 정확한 의미

### 👉 **“이상” = ‘더 극단적인 값’**

즉,

- 단순히 **오버(크다)** 만을 의미 ❌
- **틀린 부분**이라는 뜻도 ❌

👉 **관측된 통계량보다 “귀무가설에 더 불리한 방향으로” 극단적인 값**을 의미합니다.

------

## 🔍 왜 “이상”이라는 표현을 쓰는가?

p-value의 정의를 정확히 쓰면:

> **p-value는 귀무가설이 참이라는 가정 하에서,
> 관측된 통계량과 같거나 그보다 더 극단적인 값이 나올 확률이다.**

여기서 핵심은 **극단성(extremeness)** 입니다.

------

## 📌 단측 검정 vs 양측 검정에 따라 의미가 달라짐

### 1️⃣ 단측 검정 (one-sided test)

- **오른쪽 단측 검정**
  - “이상” = **관측값보다 큰 값**
- **왼쪽 단측 검정**
  - “이상” = **관측값보다 작은 값**

📍 예:

> H₁: μ > μ₀
> → p-value = P(통계량 ≥ 관측값)

------

### 2️⃣ 양측 검정 (two-sided test) ⭐️ ADP 단골

- **양쪽 모두 포함**
- “이상” = **절댓값 기준으로 더 멀리 떨어진 값**

📍 예:

> H₁: μ ≠ μ₀
> → p-value = P(|통계량| ≥ |관측값|)

------

## 🧠 직관적 비유 (시험장에서 떠올리기 좋음)

- 귀무가설 = “정상 상태”

- 관측값 = “이 정도면 이상한데?”

- p-value =

  > “정상이라고 가정했을 때,
  > **이 정도로 이상하거나 더 이상한 일이 일어날 확률**”

------

## ❌ 자주 하는 오해 정리 (시험에서 감점 원인)

| 오해                             | 정답                     |
| -------------------------------- | ------------------------ |
| “이상 = 오버”                    | ❌ (양측 검정에서는 아님) |
| “이상 = 틀린 부분”               | ❌                        |
| “p-value는 귀무가설이 틀릴 확률” | ❌                        |
| “p-value는 극단성의 확률”        | ⭕                        |

------

## ✍️ ADP 시험용 **완벽한 문장**

> p-value는 귀무가설이 참이라는 가정 하에서,
> **관측된 통계량과 같거나 그보다 더 극단적인 값이 발생할 확률**이다.

👉 이 문장은 **채점 기준에 정확히 부합**합니다.

------

## 🔥 한 단계 더 (고득점 포인트)

시험에서 이렇게 한 줄 더 쓰면 **상위권 답안**입니다.

> 단측 검정에서는 한쪽 방향의 극단성을,
> 양측 검정에서는 양쪽 방향의 극단성을 고려한다.

------

원하시면 다음으로
👉 **“p-value vs 유의수준 α의 관계를 헷갈리지 않게 설명하는 법”**
또는
👉 **“양측검정을 기본으로 쓰는 이유(실무·시험 관점)”**
바로 이어서 정리해 드릴게요.

